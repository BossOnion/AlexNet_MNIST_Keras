{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 使用GPU进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# print('tensorflow version:',tf.__version__)  # 查看TensorFlow的版本\n",
    "# print('===================================================')\n",
    "# print('cuda available:',tf.test.is_built_with_cuda()) # 判断CUDA是否可用\n",
    "# print('===================================================')\n",
    "# print(tf.test.is_gpu_available())  # 查看cuda、TensorFlow_GPU和cudnn(选择下载，cuda对深度学习的补充)版本是否对应\n",
    "# print('===================================================')\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU') # 查看可用GPU\n",
    "# print(gpus)\n",
    "import os\n",
    "#选择使用某一块或多块GPU\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # =右边\"0,1\",代表使用标号为0,和1的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # =右边\"0\",代表使用标号为0的GPU\n",
    "# 查看可用GPU的详细信息\n",
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "#  这时候在运行相应的代码，就可以看到在GPU上运行了。可以通过任务管理器-性能处查看GPU使用率。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调整后的训练图像形状: (6000, 227, 227, 3)\n",
      "调整后的测试图像形状: (1000, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "# 首先加载MNIST数据集。然后，通过循环遍历每个图像，使用OpenCV库的cvtColor函数将灰度图像转换为RGB格式（因为AlexNet需要RGB图像作为输入）。\n",
    "# 接下来，使用resize函数将图像大小调整为227x227。调整后的图像被添加到相应的列表中。最后，使用np.array将图像列表转换为NumPy数组。\n",
    "# 由于MNIST数据集中的图像是灰度图像（单通道），因此在转换为RGB格式之前需要将其从二维数组调整为三维数组（添加一个额外的维度）。\n",
    "# 这可以通过使用np.expand_dims函数来实现。\n",
    "\n",
    "# 加载手写数字数据集（MNIST）\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) =mnist.load_data(\"mnist.npz\") # 加载本地的mnist数据集\n",
    "\n",
    "# 将图像大小调整为227x227\n",
    "resized_train_images = []\n",
    "resized_test_images = []\n",
    "\n",
    "# 由于电脑性能有限，未训练全部mnist数据集，仅选择其中一部分为keras_alexnet做工程验证\n",
    "\n",
    "train_labels=train_labels[:6000]\n",
    "test_labels=test_labels[:1000]\n",
    "\n",
    "for image in train_images[:6000]:\n",
    "    # 将图像从灰度转换为RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) \n",
    "    # 调整图像大小为227x227\n",
    "    resized_image = cv2.resize(image_rgb, (227, 227))\n",
    "    # 添加调整后的图像到列表\n",
    "    resized_train_images.append(resized_image)\n",
    "\n",
    "for image in test_images[:1000]:\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    resized_image = cv2.resize(image_rgb, (227, 227))\n",
    "    resized_test_images.append(resized_image)\n",
    "\n",
    "# 将图像列表转换为 NumPy数组 并 归一化\n",
    "resized_train_images = np.array(resized_train_images).astype('float32') / 255.0\n",
    "resized_test_images = np.array(resized_test_images).astype('float32') / 255.0\n",
    "\n",
    "# 输出调整后图像的形状\n",
    "print(\"调整后的训练图像形状:\", resized_train_images.shape)\n",
    "print(\"调整后的测试图像形状:\", resized_test_images.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 构建AlexNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 构建AlexNet模型\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(227, 227, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 训练AlexNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 2.8267 - accuracy: 0.6973 - val_loss: 1.6012 - val_accuracy: 0.6950\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 36s 120ms/step - loss: 0.9157 - accuracy: 0.8218 - val_loss: 1.3226 - val_accuracy: 0.6670\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.6454 - accuracy: 0.8587 - val_loss: 0.6813 - val_accuracy: 0.8850\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.7304 - accuracy: 0.8373 - val_loss: 0.6860 - val_accuracy: 0.9040\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.5616 - accuracy: 0.8757 - val_loss: 0.4872 - val_accuracy: 0.9040\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.6376 - accuracy: 0.8620 - val_loss: 1.0980 - val_accuracy: 0.8660\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.6529 - accuracy: 0.8650 - val_loss: 0.4006 - val_accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.5657 - accuracy: 0.8807 - val_loss: 0.4335 - val_accuracy: 0.8940\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.6789 - accuracy: 0.8408 - val_loss: 0.3530 - val_accuracy: 0.9120\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.6923 - accuracy: 0.8463 - val_loss: 0.6543 - val_accuracy: 0.7820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c988c66288>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编译和训练模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(resized_train_images, train_labels, epochs=10, batch_size=20, validation_data=(resized_test_images, test_labels))\n",
    "# 电脑性能有限，仅选择部分数据进行模型的训练和测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 显示模型信息并保存为.h5文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 58,327,818\n",
      "Trainable params: 58,325,066\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 保存模型\n",
    "model.save('alexnet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
