{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 使用CPU进行模型的测试与转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 使用自定义图片测试.h5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 390ms/step\n",
      "num 0 预测结果： 0\n",
      "num 1 预测结果： 1\n",
      "num 2 预测结果： 2\n",
      "num 3 预测结果： 3\n",
      "num 4 预测结果： 4\n",
      "num 5 预测结果： 5\n",
      "num 6 预测结果： 6\n",
      "num 7 预测结果： 7\n",
      "num 8 预测结果： 8\n",
      "num 9 预测结果： 9\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model=models.load_model('alexnet.h5')\n",
    "# 读取测试数据-10张手写数字图片-预处理\n",
    "num_image=list()\n",
    "for i in range(10):\n",
    "    img_path='handwrite_num/{}.png'.format(i)\n",
    "    num_image.append(cv2.resize(cv2.imread(img_path,cv2.IMREAD_COLOR).astype('float32'),(227,227))/255.0)\n",
    "input_image = np.array(num_image)\n",
    "# 对模型进行预测\n",
    "predictions = model.predict(input_image)\n",
    "# 获取预测结果中概率最高的类别\n",
    "for i in range(10):\n",
    "    print(\"num\",i,\"预测结果：\", np.argmax(predictions[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 将模型转换为tflite格式并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp1tvk6etg\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp1tvk6etg\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "233308828"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将keras模型转换为tflite格式\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "# 保存alexnet-tflite模型\n",
    "tflite_name = \"alexnet.tflite\"\n",
    "open(tflite_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 测试tflite格式的alexnet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num 0 预测结果 0\n",
      "num 1 预测结果 1\n",
      "num 2 预测结果 2\n",
      "num 3 预测结果 3\n",
      "num 4 预测结果 4\n",
      "num 5 预测结果 5\n",
      "num 6 预测结果 6\n",
      "num 7 预测结果 7\n",
      "num 8 预测结果 8\n",
      "num 9 预测结果 9\n"
     ]
    }
   ],
   "source": [
    "# 加载TFLite模型\n",
    "interpreter = tf.lite.Interpreter(model_path='alexnet.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 获取输入和输出张量的索引\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 读取测试数据-10张手写数字图片-预处理\n",
    "num_image=list()\n",
    "for i in range(10):\n",
    "    img_path='handwrite_num/{}.png'.format(i)\n",
    "    num_image.append(cv2.resize(cv2.imread(img_path,cv2.IMREAD_COLOR).astype('float32'),(227,227))/255.0)\n",
    "input_data = np.array(num_image)\n",
    "\n",
    "for i in range(10):\n",
    "    test_image=input_data[i].reshape((1,227,227,3))\n",
    "    # 设置输入张量的值\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    # 运行模型\n",
    "    interpreter.invoke()\n",
    "    # 获取输出张量的值\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print('num',i,'预测结果',np.argmax(output_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 对h5格式的alexnet模型进行int8量化，并保存为tflite格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp8ezgmtq6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp8ezgmtq6\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58387408"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载Keras模型\n",
    "keras_model = tf.keras.models.load_model('alexnet.h5')\n",
    "# 将Keras模型转换为TfLite模型\n",
    "converter_quant = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "# set the optimization parameters for TensorFlow Lite conversion\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# convert the model to TensorFlow Lite format with float32 activations and int8 weights\n",
    "alexnet_quanitfied_model = converter_quant.convert()\n",
    "\n",
    "#保存转换后的模型\n",
    "alexnet_quanitfied_name = \"alexnet_quanitfied.tflite\"\n",
    "open(alexnet_quanitfied_name, \"wb\").write(alexnet_quanitfied_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 测试int8量化后的AlexNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num 0 预测结果 0\n",
      "num 1 预测结果 1\n",
      "num 2 预测结果 2\n",
      "num 3 预测结果 3\n",
      "num 4 预测结果 4\n",
      "num 5 预测结果 5\n",
      "num 6 预测结果 6\n",
      "num 7 预测结果 7\n",
      "num 8 预测结果 8\n",
      "num 9 预测结果 9\n"
     ]
    }
   ],
   "source": [
    "# 加载量化后的TFLite模型\n",
    "interpreter = tf.lite.Interpreter(model_path='alexnet_quanitfied.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 获取输入和输出张量的索引\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 读取测试数据-10张手写数字图片-预处理\n",
    "num_image=list()\n",
    "for i in range(10):\n",
    "    img_path='handwrite_num/{}.png'.format(i)\n",
    "    num_image.append(cv2.resize(cv2.imread(img_path,cv2.IMREAD_COLOR).astype('float32'),(227,227))/255.0)\n",
    "input_data = np.array(num_image)\n",
    "\n",
    "for i in range(10):\n",
    "    test_image=input_data[i].reshape((1,227,227,3))\n",
    "    # 设置输入张量的值\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    # 运行模型\n",
    "    interpreter.invoke()\n",
    "    # 获取输出张量的值\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print('num',i,'预测结果',np.argmax(output_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 错误"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若采用以下方法进行int8量化，理论上可生成激活值（偏置）为int64、权重为int8的tflite模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是会遇到输入张量的维度不符合模型期望的问题，目前尚未解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpi7gwfnxd\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpi7gwfnxd\\assets\n",
      "d:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tensorflow/lite/kernels/conv.cc:343 input->dims->size != 4 (3 != 4)Node number 0 (CONV_2D) failed to prepare.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m converter_quant\u001b[39m.\u001b[39mrepresentative_dataset \u001b[39m=\u001b[39m representative_data_gen\n\u001b[0;32m     21\u001b[0m \u001b[39m# convert the model to TensorFlow Lite format with int64 activations and int8 weights\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m quantified_AlexNet_model \u001b[39m=\u001b[39m converter_quant\u001b[39m.\u001b[39;49mconvert()\n\u001b[0;32m     24\u001b[0m \u001b[39m#保存转换后的模型\u001b[39;00m\n\u001b[0;32m     25\u001b[0m quantified_AlexNet_model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mquantified_AlexNet_model.tflite\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:933\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[0;32m    931\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    932\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:911\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m    910\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m--> 911\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    912\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1342\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[39m@_export_metrics\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1331\u001b[0m   \u001b[39m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \n\u001b[0;32m   1333\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1340\u001b[0m \u001b[39m      Invalid quantization parameters.\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m   saved_model_convert_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_as_saved_model()\n\u001b[0;32m   1343\u001b[0m   \u001b[39mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1324\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   graph_def, input_tensors, output_tensors \u001b[39m=\u001b[39m (\n\u001b[0;32m   1322\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_keras_to_saved_model(temp_dir))\n\u001b[0;32m   1323\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msaved_model_dir:\n\u001b[1;32m-> 1324\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFLiteKerasModelConverterV2,\n\u001b[0;32m   1325\u001b[0m                  \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert(graph_def, input_tensors, output_tensors)\n\u001b[0;32m   1326\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m   shutil\u001b[39m.\u001b[39mrmtree(temp_dir, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1141\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m# Converts model.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m result \u001b[39m=\u001b[39m _convert_graphdef(\n\u001b[0;32m   1136\u001b[0m     input_data\u001b[39m=\u001b[39mgraph_def,\n\u001b[0;32m   1137\u001b[0m     input_tensors\u001b[39m=\u001b[39minput_tensors,\n\u001b[0;32m   1138\u001b[0m     output_tensors\u001b[39m=\u001b[39moutput_tensors,\n\u001b[0;32m   1139\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconverter_kwargs)\n\u001b[1;32m-> 1141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimize_tflite_model(\n\u001b[0;32m   1142\u001b[0m     result, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quant_mode, quant_io\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_new_quantizer)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:871\u001b[0m, in \u001b[0;36mTFLiteConverterBase._optimize_tflite_model\u001b[1;34m(self, model, quant_mode, quant_io)\u001b[0m\n\u001b[0;32m    869\u001b[0m   q_bias_type \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mbias_type()\n\u001b[0;32m    870\u001b[0m   q_allow_float \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mis_allow_float()\n\u001b[1;32m--> 871\u001b[0m   model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quantize(model, q_in_type, q_out_type, q_activations_type,\n\u001b[0;32m    872\u001b[0m                          q_bias_type, q_allow_float)\n\u001b[0;32m    874\u001b[0m m_in_type \u001b[39m=\u001b[39m in_type \u001b[39mif\u001b[39;00m in_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m    875\u001b[0m m_out_type \u001b[39m=\u001b[39m out_type \u001b[39mif\u001b[39;00m out_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:613\u001b[0m, in \u001b[0;36mTFLiteConverterBase._quantize\u001b[1;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float)\u001b[0m\n\u001b[0;32m    609\u001b[0m calibrate_quantize \u001b[39m=\u001b[39m _calibrator\u001b[39m.\u001b[39mCalibrator(result,\n\u001b[0;32m    610\u001b[0m                                             custom_op_registerers_by_name,\n\u001b[0;32m    611\u001b[0m                                             custom_op_registerers_by_func)\n\u001b[0;32m    612\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_new_quantizer:\n\u001b[1;32m--> 613\u001b[0m   calibrated \u001b[39m=\u001b[39m calibrate_quantize\u001b[39m.\u001b[39;49mcalibrate(\n\u001b[0;32m    614\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentative_dataset\u001b[39m.\u001b[39;49minput_gen)\n\u001b[0;32m    616\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only:\n\u001b[0;32m    617\u001b[0m   \u001b[39mreturn\u001b[39;00m calibrated\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py:226\u001b[0m, in \u001b[0;36mCalibrator.calibrate\u001b[1;34m(self, dataset_gen)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m@convert_phase\u001b[39m(Component\u001b[39m.\u001b[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001b[39m.\u001b[39mCALIBRATE)\n\u001b[0;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalibrate\u001b[39m(\u001b[39mself\u001b[39m, dataset_gen):\n\u001b[0;32m    218\u001b[0m   \u001b[39m\"\"\"Calibrates the model with specified generator.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m    dataset_gen: A generator that generates calibration samples.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed_tensors(dataset_gen, resize_input\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    227\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mCalibrate()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py:129\u001b[0m, in \u001b[0;36mCalibrator._feed_tensors\u001b[1;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mPrepare([\u001b[39mlist\u001b[39m(s\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m input_array],\n\u001b[0;32m    127\u001b[0m                              signature_key)\n\u001b[0;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calibrator\u001b[39m.\u001b[39;49mPrepare([\u001b[39mlist\u001b[39;49m(s\u001b[39m.\u001b[39;49mshape) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m input_array])\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m   \u001b[39mif\u001b[39;00m signature_key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tensorflow/lite/kernels/conv.cc:343 input->dims->size != 4 (3 != 4)Node number 0 (CONV_2D) failed to prepare."
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载Keras模型\n",
    "keras_model = tf.keras.models.load_model('alexnet.h5')\n",
    "# 将Keras模型转换为TfLite模型\n",
    "converter_quant = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "# set the optimization parameters for TensorFlow Lite conversion\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# 选择量化策略\n",
    "converter_quant.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] \n",
    "# load the MNIST dataset and prepare it for representative data generation\n",
    "mnist_train, _ = tf.keras.datasets.mnist.load_data(\"mnist.npz\")\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "# define a generator function for representative data\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "# set the representative dataset for the converter\n",
    "converter_quant.representative_dataset = representative_data_gen\n",
    "\n",
    "# convert the model to TensorFlow Lite format with int64 activations and int8 weights\n",
    "quantified_AlexNet_model = converter_quant.convert()\n",
    "\n",
    "#保存转换后的模型\n",
    "quantified_AlexNet_model_name = \"quantified_AlexNet_model.tflite\"\n",
    "open(quantified_AlexNet_model_name, \"wb\").write(quantified_AlexNet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
